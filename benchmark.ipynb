{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import datetime\n",
    "import json\n",
    "import numpy\n",
    "import os\n",
    "import queue\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "CWD = os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.insert(0, os.path.join(CWD, \"lib\"))\n",
    "\n",
    "REPORT = re.compile(\".*Duration:\\s([0-9\\.]+)\\sms.*Billed Duration:\\s([0-9\\.]+)\\sms.*Memory Size:\\s([0-9]+)\\sMB.*Max Memory Used:\\s([0-9]+)\\sMB.*\")\n",
    "SPECTRA = re.compile(\"S\\s\\d+.*\")\n",
    "INTENSITY = re.compile(\"I\\s+MS1Intensity\\s+([0-9\\.]+)\")\n",
    "MEMORY_PARAMETERS = json.loads(open(\"json/memory.json\").read())\n",
    "\n",
    "def upload_functions(client, params):\n",
    "  functions = [\"split_spectra\", \"analyze_spectra\", \"combine_spectra_results\", \"percolator\"]\n",
    "\n",
    "  os.chdir(\"lambda\")\n",
    "  for function in functions:\n",
    "    fparams = json.loads(open(\"../json/{0:s}.json\".format(function)).read())\n",
    "    subprocess.call(\"zip {0:s}.zip {0:s}.py\".format(function), shell=True)\n",
    "\n",
    "    with open(\"{0:s}.zip\".format(function), \"rb\") as f:\n",
    "      zipped_code = f.read()\n",
    "\n",
    "    response = client.update_function_code(\n",
    "      FunctionName=fparams[\"name\"],\n",
    "      ZipFile=zipped_code,\n",
    "    )\n",
    "    assert(response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200)\n",
    "\n",
    "    response = client.update_function_configuration(\n",
    "      FunctionName=fparams[\"name\"],\n",
    "      Timeout=fparams[\"timeout\"],\n",
    "      MemorySize=fparams[\"memory_size\"]\n",
    "    )\n",
    "    assert(response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200)\n",
    "\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "# TODO: Remove once we incorporate this into the split lambda function\n",
    "def process():\n",
    "  print(\"process\")\n",
    "  subprocess.call(\"rm lambda/sorted-small-*\", shell=True)\n",
    "  f = open(\"lambda/small.ms2\")\n",
    "  lines = f.readlines()[1:]\n",
    "  f.close()\n",
    "\n",
    "  spectrum = []\n",
    "  intensity = None\n",
    "  spectra = []\n",
    "\n",
    "  for line in lines:\n",
    "    if SPECTRA.match(line):\n",
    "      if intensity is not None:\n",
    "        spectrum.append((intensity, \"\".join(spectra)))\n",
    "        intensity = None\n",
    "        spectra = []\n",
    "\n",
    "    m = INTENSITY.match(line)\n",
    "    if m:\n",
    "      intensity = float(m.group(1))\n",
    "\n",
    "    spectra.append(line)\n",
    "\n",
    "  spectrum = sorted(spectrum, key=lambda spectra: -spectra[0])\n",
    "\n",
    "  offset = 260\n",
    "  i = 0\n",
    "  print(\"offset\", offset)\n",
    "  while i * offset < min(len(spectrum), 1):\n",
    "    index = i * offset\n",
    "    f = open(\"lambda/sorted-small-{0:d}.ms2\".format(i), \"w+\")\n",
    "    f.write(\"H Extractor MzXML2Search\\n\")\n",
    "    for spectra in spectrum[index:min(index+offset, len(spectrum))]:\n",
    "      for line in spectra[1]:\n",
    "        f.write(line)\n",
    "    i += 1\n",
    "  return i\n",
    "\n",
    "def upload_input():\n",
    "  bucket_name = \"maccoss-human-input-spectra\"\n",
    "  key = \"20170403_HelaQC_01.ms2\"\n",
    "  s3 = boto3.resource(\"s3\")\n",
    "  s3.Object(bucket_name, key).put(Body=open(key, 'rb'))\n",
    "  obj = s3.Object(bucket_name, key)\n",
    "  print(key, \"last modified\", obj.last_modified)\n",
    "  timestamp = obj.last_modified.timestamp()\n",
    "  return int(timestamp)\n",
    "\n",
    "def check_objects(client, bucket_name, prefix, count):\n",
    "  done = False\n",
    "  suffix = \"\"\n",
    "  if count > 1:\n",
    "    suffix = \"s\"\n",
    "  while not done:\n",
    "    response = client.list_objects(\n",
    "      Bucket=bucket_name,\n",
    "      Prefix=prefix\n",
    "    )\n",
    "    done = ((\"Contents\" in response) and (len(response[\"Contents\"]) == count))\n",
    "    now = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "    if not done:\n",
    "      print(\"{0:s}: Waiting for {1:s} function{2:s}...\".format(now, prefix, suffix))\n",
    "      time.sleep(60)\n",
    "    else:\n",
    "      print(\"{0:s}: Found {1:s} function{2:s}\".format(now, prefix, suffix))\n",
    "\n",
    "def wait_for_completion(params):\n",
    "  client = boto3.client(\"s3\", region_name=params[\"region\"])\n",
    "  bucket_name = \"maccoss-human-output-spectra\"\n",
    "\n",
    "  check_objects(client, bucket_name, \"combined\", 1)\n",
    "  check_objects(client, bucket_name, \"decoy\", 2)\n",
    "  check_objects(client, bucket_name, \"target\", 2)\n",
    "  print(\"\")\n",
    "\n",
    "def fetch_events(client, num_events, log_name, start_time, filter_pattern):\n",
    "  events = []\n",
    "  next_token = None\n",
    "  while len(events) < num_events:\n",
    "    args = {\n",
    "      \"filterPattern\": filter_pattern,\n",
    "      \"limit\": num_events - len(events),\n",
    "      \"logGroupName\": \"/aws/lambda/{0:s}\".format(log_name),\n",
    "      \"startTime\": start_time\n",
    "    }\n",
    "\n",
    "    if next_token:\n",
    "      args[\"nextToken\"] = next_token\n",
    "\n",
    "    response = client.filter_log_events(**args)\n",
    "    next_token = response[\"nextToken\"]\n",
    "    events += response[\"events\"]\n",
    "\n",
    "  assert(len(events) == num_events)\n",
    "  return events\n",
    "\n",
    "def calculate_cost(duration, memory_size):\n",
    "  # Cost per 100ms\n",
    "  millisecond_cost = MEMORY_PARAMETERS[str(memory_size)]\n",
    "  return int(duration / 100) * millisecond_cost\n",
    "\n",
    "def parse_split_logs(client, start_time):\n",
    "  sparams = json.loads(open(\"json/split_spectra.json\").read())\n",
    "  events = fetch_events(client, 1, \"SplitSpectra\", start_time, \"REPORT RequestId\")\n",
    "  m = REPORT.match(events[0][\"message\"])\n",
    "  duration = int(m.group(2))\n",
    "  memory_used = int(m.group(4))\n",
    "  cost = calculate_cost(duration, sparams[\"memory_size\"])\n",
    "\n",
    "  print(\"Split Spectra\")\n",
    "  print(\"Timestamp\", events[0][\"timestamp\"])\n",
    "  print(\"Billed Duration\", duration, \"milliseconds\")\n",
    "  print(\"Max Memory Used\", m.group(4))\n",
    "  print(\"Cost\", cost)\n",
    "  print(\"\")\n",
    "\n",
    "  return {\n",
    "    \"billed_duration\": duration,\n",
    "    \"max_duration\": duration,\n",
    "    \"memory_used\": memory_used,\n",
    "    \"cost\": cost\n",
    "  }\n",
    "\n",
    "def parse_analyze_logs(client, start_time):\n",
    "  num_lambdas = 42 # TODO: Unhardcode\n",
    "  events = fetch_events(client, num_lambdas, \"AnalyzeSpectra\", start_time, \"REPORT RequestId\")\n",
    "  aparams = json.loads(open(\"json/analyze_spectra.json\").read())\n",
    "  max_billed_duration = 0\n",
    "  total_billed_duration = 0\n",
    "  total_memory_used = 0 # TODO: Handle\n",
    "  min_timestamp = events[0][\"timestamp\"]\n",
    "  max_timestamp = events[0][\"timestamp\"]\n",
    "\n",
    "  for event in events:\n",
    "    min_timestamp = min(timestamp, event[\"timestamp\"])\n",
    "    max_timestamp = max(timestamp, event[\"timestamp\"])\n",
    "    m = REPORT.match(event[\"message\"])\n",
    "    duration = int(m.group(2))\n",
    "    memory_used = int(m.group(4))\n",
    "    max_billed_duration = max(max_billed_duration, duration)\n",
    "    total_billed_duration += duration\n",
    "    total_memory_used += memory_used\n",
    "\n",
    "  cost = calculate_cost(total_billed_duration, aparams[\"memory_size\"])\n",
    "\n",
    "  print(\"Analyze Spectra\")\n",
    "  print(\"Min Timestamp\", min_timestamp)\n",
    "  print(\"Max Timestamp\", max_timestamp)\n",
    "  print(\"Max Billed Duration\", max_billed_duration, \"milliseconds\")\n",
    "  print(\"Total Billed Duration\", total_billed_duration, \"milliseconds\")\n",
    "  print(\"Cost\", cost)\n",
    "  print(\"\")\n",
    "\n",
    "  return {\n",
    "    \"billed_duration\": total_billed_duration,\n",
    "    \"max_duration\": max_billed_duration,\n",
    "    \"memory_used\": total_memory_used,\n",
    "    \"cost\": cost\n",
    "  }\n",
    "\n",
    "def parse_combine_logs(client, start_time):\n",
    "  cparams = json.loads(open(\"json/combine_spectra_results.json\").read())\n",
    "  events = fetch_events(client, 1, \"CombineSpectraResults\", start_time, \"Combining\")\n",
    "  response = client.filter_log_events(\n",
    "    logGroupName=\"/aws/lambda/CombineSpectraResults\",\n",
    "    logStreamNames=[events[0][\"logStreamName\"]],\n",
    "    startTime=events[0][\"timestamp\"],\n",
    "    filterPattern=\"REPORT RequestId\",\n",
    "    limit = 1\n",
    "  )\n",
    "  assert(len(response[\"events\"]) == 1)\n",
    "  m = REPORT.match(response[\"events\"][0][\"message\"])\n",
    "  duration = int(m.group(2))\n",
    "  memory_used = int(m.group(4))\n",
    "  cost = calculate_cost(duration, cparams[\"memory_size\"])\n",
    "\n",
    "  print(\"Combine Spectra\")\n",
    "  print(\"Timestamp\", events[0][timestamp])\n",
    "  print(\"Billed Duration\", duration, \"milliseconds\")\n",
    "  print(\"Max Memory Used\", m.group(4))\n",
    "  print(\"Cost\", cost)\n",
    "  print(\"\")\n",
    "\n",
    "  return {\n",
    "    \"billed_duration\": duration,\n",
    "    \"max_duration\": duration,\n",
    "    \"memory_used\": memory_used,\n",
    "    \"cost\": cost\n",
    "  }\n",
    "\n",
    "def parse_percolator_logs(client, start_time):\n",
    "  pparams = json.loads(open(\"json/percolator.json\").read())\n",
    "  events = fetch_events(client, 1, \"Percolator\", start_time, \"REPORT RequestId\")\n",
    "  m = REPORT.match(events[0][\"message\"])\n",
    "  duration = int(m.group(2))\n",
    "  memory_used = int(m.group(4))\n",
    "  cost = calculate_cost(duration, pparams[\"memory_size\"])\n",
    "\n",
    "  print(\"Percolator Spectra\")\n",
    "  print(\"Timestamp\", events[0][timestamp])\n",
    "  print(\"Billed Duration\", duration, \"milliseconds\")\n",
    "  print(\"Max Memory Used\", m.group(4))\n",
    "  print(\"Cost\", cost)\n",
    "  print(\"\")\n",
    "\n",
    "  return {\n",
    "    \"billed_duration\": duration,\n",
    "    \"max_duration\": duration,\n",
    "    \"memory_used\": memory_used,\n",
    "    \"cost\": cost\n",
    "  }\n",
    "\n",
    "def parse_logs(params, upload_timestamp):\n",
    "  client = boto3.client(\"logs\", region_name=params[\"region\"])\n",
    "  stats = []\n",
    "  stats.append(parse_split_logs(client, upload_timestamp))\n",
    "  stats.append(parse_analyze_logs(client, upload_timestamp))\n",
    "  stats.append(parse_combine_logs(client, upload_timestamp))\n",
    "  stats.append(parse_percolator_logs(client, upload_timestamp))\n",
    "\n",
    "  cost = 0\n",
    "  max_duration = 0\n",
    "  billed_duration = 0\n",
    "  memory_used = 0\n",
    "\n",
    "  for stat in stats:\n",
    "    cost += stat[\"cost\"]\n",
    "    max_duration += stat[\"max_duration\"]\n",
    "    billed_duration += stat[\"billed_duration\"]\n",
    "    memory_used += stat[\"memory_used\"]\n",
    "\n",
    "  print(\"END RESULTS\")\n",
    "  print(\"Total Cost\", cost)\n",
    "  print(\"Total Runtime\", max_duration, \"milliseconds\")\n",
    "  print(\"Total Billed Duration\", billed_duration, \"milliseconds\")\n",
    "  print(\"Total Memory Used\", memory_used, \"MB\")\n",
    "\n",
    "  return {\n",
    "    \"cost\": cost,\n",
    "    \"max_duration\": max_duration,\n",
    "    \"billed_duration\": billed_duration,\n",
    "    \"memory_used\": memory_used\n",
    "  }\n",
    "\n",
    "def clear_buckets():\n",
    "  s3 = boto3.resource(\"s3\")\n",
    "  for bucket_name in [\"maccoss-human-input-spectra\", \"maccoss-human-split-spectra\", \"maccoss-human-output-spectra\"]:\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    bucket.objects.all().delete()\n",
    "\n",
    "def benchmark(params):\n",
    "  clear_buckets()\n",
    "  upload_timestamp = upload_input()\n",
    "  wait_for_completion(params)\n",
    "  return parse_logs(params, upload_timestamp)\n",
    "\n",
    "def run(params):\n",
    "  print(\"Current Git commit\", subprocess.check_output(\"git rev-parse HEAD\", shell=True).decode(\"utf-8\").strip())\n",
    "  iterations = params[\"iterations\"]\n",
    "  extra_time = 20\n",
    "  config = Config(read_timeout=params[\"timeout\"] + extra_time)\n",
    "  client = boto3.client(\"lambda\", region_name=params[\"region\"], config=config)\n",
    "  # https://github.com/boto/boto3/issues/1104#issuecomment-305136266\n",
    "  # boto3 by default retries even if max timeout is set. This is a workaround.\n",
    "  client.meta.events._unique_id_handlers['retry-config-lambda']['handler']._checker.__dict__['_max_attempts'] = 0\n",
    "\n",
    "  upload_functions(client, params)\n",
    "\n",
    "  cost = 0\n",
    "  max_duration = 0\n",
    "  billed_duration = 0\n",
    "  memory_used = 0\n",
    "  for i in range(iterations):\n",
    "    print(\"Iteration {0:d}\".format(i))\n",
    "    results = benchmark(params)\n",
    "    cost += results[\"cost\"]\n",
    "    max_duration += results[\"max_duration\"]\n",
    "    billed_duration += results[\"billed_duration\"]\n",
    "    memory_used += results[\"memory_used\"]\n",
    "    print(\"--------------------------\")\n",
    "    print(\"\")\n",
    "\n",
    "  cost = float(cost) / iterations\n",
    "  max_duration = float(max_duration) / iterations\n",
    "  billed_duration = float(billed_duration) / iterations\n",
    "  memory_used = float(memory_used) / iterations\n",
    "\n",
    "  print(\"AVERAGE RESULTS ({0:d} ITERATIONS)\".format(iterations))\n",
    "  print(\"Average Cost\", cost)\n",
    "  print(\"Average Runtime\", max_duration, \"milliseconds\")\n",
    "  print(\"Average Billed Duration\", billed_duration, \"milliseconds\")\n",
    "  print(\"Average Memory Used\", memory_used, \"MB\")\n",
    "\n",
    "\n",
    "def main():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--parameters', type=str, required=True, help=\"File containing parameters\")\n",
    "  args = parser.parse_args()\n",
    "  params = json.loads(open(args.parameters).read())\n",
    "  run(params)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
